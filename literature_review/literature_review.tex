\chapter{Literature Review}
This section will discuss the background literature relating to this project.

\section{Machine Learning}
Classification is the process of mapping observations into predefined classes, based on a set of training data. Some classification algorithms include Decision Tree, Support Vector Machine (SVM), Naïve Bayes, Random Forest, K-means, Logistic Regression and Nearest Neighbour.

There are two main approaches to text classification using machine learning; supervised and unsupervised learning. Supervised learning involves labelled data. There are input variables (x) and output variables (y) and an algorithm is used to train the mapping function from the input to the output (y = f(x)). This mapping function that has been trained is then applied to new unseen data. Unsupervised learning, uses unlabelled data and only has input variables (x) with no output variables. An algorithm is used to find patterns directly from the data. It is generally not used for classification but to discover unknown patterns in data. A supervised machine learning approach will be taken in this research.

A Support Vector Machine (SVM) is a discriminative classifier, first introduced by Cortes and Vapnik \cite{Vapnik1995,Vapnik21995}. It finds the optimum hyperplane that separates the data into classes. The aim of a SVM is to maximise the margin (distance) between the hyperplane and the support vectors (data points closest to the hyperplane). SVMs have been used successfully for text classification \textcolor{red}{EXAMPLES}.

Naïve Bayes (NB) is a popular supervised learning method for text classification. It is a probabilistic classifier, calculating the probability that an observation belongs to a particular class. NB is based on applying Bayes Rule along with the ‘naïve’ assumption that features are conditionally independent. In the case of text classification, this assumes all words are independent, which is untrue. Bayes Rule is as follows:  \[P(A\mid B)=\frac{P(B\mid A)\:P(A)}{P(B)}\] 

A. Bermingham and A. F. Smeaton \cite{Berm2010} investigate the performance of both Support Vector Machines (SVM) and Multinomial Naïve Bayes (MNB) in classifying the sentiment of short versus long form documents. The short form documents used were microblogs from Twitter and micro-reviews from Blippr. The long form documents were TREC Blog06 Corpus and Pang and Lees Movie Review Corpus \cite{panglee2004}. A maximum accuracy of 74.85\% was achieved with MNB versus 73.45\% with SVM. Overall MNB achieves better accuracy than SVM on the short form documents, suggesting that MNB may be useful for the classification of tweets as reviews.

Another point of interest is the kind of feature extraction that performed well for the long versus short form documents. Extending the unigram feature representation improved classification accuracy for the long form documents, but did not for the short form documents. However POS (part-of-speech) features and punctuation aided classification of the short form documents. 

Logistic Regression (LR) is a linear classifier. LR uses the logistic function, known also as the sigmoid function or logit function to model the data. This is an S-shaped curve, taking real valued inputs and mapping them to the range 0 – 1. The logistic function is as follows: \[g(z)=1/(1+e^{-z})\]
LR models the probability that an observation belongs to a particular class. The coefficients of the LR algorithm are estimated from the training data, using maximum likelihood estimation or gradient descent.

\textcolor{red}{LR for text classfication}

An Ensemble Classifier aggregates various individual base classifiers. It has been demonstrated that an ensemble classifier generally performs better than individual classifiers \cite{Opitz1999}. Ankit and N. Saleena \cite{Ankit2018} propose an ensemble classifier for the sentiment analysis of tweets. The base classifiers include Naive Bayes, Random Forest, Support Vector Machine and Logistic Regression. The ensemble classifier outperforms each of the individual base classifiers.
\textcolor{red}{Two possible ensemble techniques are boosting and bagging.}

A. Go, R. Bhayani, and L. Huang \cite{Go2009} proposed the  idea of creating a training set of tweets, labelled as positive or negative based on the emoticons they contain. The dataset produced (Stanford Sentiment 140) was used to train Naive Bayes, Maximum Entropy, and Support Vector Machine classifiers. They report the best accuracy (83\%) with the Maximum Entropy Classifier. Their work helped address the problem of creating large labelled datasets to train classifiers. This can be a very time-consuming, costly and labour-intensive process. The dataset produced has been used in many other studies, including the above mentioned Ensemble Classifier study \cite{Ankit2018}.

\textcolor{red}{How does the Max Ent work?}

A. Rane and A. Kumar compare seven different classifiers (Decision Tree, Random Forest, SVM, K-Nearest Neighbours, Logistic Regression, Gaussian Naïve Bayes and AdaBoost) for the sentiment analysis of Twitter Data about US Airline Services \cite{Rane2018}. 
\begin{wrapfigure}{r}{0.5\textwidth}
    \centering
    \includegraphics[width=0.5\textwidth]{literature_review/arane_classifier_results.PNG}
    \caption{Accuracy of Classifier Results from the study by A. Rane and A. Kumar \cite{Rane2018}}
\end{wrapfigure}
The Random Forest Classifier performed the best, with reported precision of 85.6\%. The research makes use of doc2vec.

\textcolor{red}{How does Random Forest work?}

\textcolor{red}{Feature Representation: DOC2VEC}

M. Rathi, A. Malik, D. Varshney, R. Sharma, and S. Mendiratta \cite{Raithi2018} tested SVM, Adaboosted Decision Tree and Decision Tree Classifiers, for the sentiment analysis of tweets. TFIDF (term frequency inverse document frequency) Vectorization is applied during pre-processing. Using TFIDF gives a measure of how important a word is within the dataset. A word that is frequent in an individual document but infrequent in the dataset is considered important. The weights from TFIDF are applied to the dataset emphasising the contribution of some words and reducing the contribution of others. They found the Decision Tree Classifier performed best  (accuracy: 84\%) followed by the SVM (accuracy: 82\%) and then the Adaboosted (accuracy: 67\%). 



\section{Sentiment Analysis}

The Sentiment Analyzer from the Stanford NLP (Natural Language Processing) Group \cite{stanfordSentiment2013} introduces a Recursive Neural Tensor Network (RNTN). The RNTN is trained on a Sentiment Treebank. A corpus of movie reviews originally collected by Pang and Lee was used \cite{panglee2004} is used as the basis of the Sentiment Treebank. The sentences in the corpus are parsed into phrases, producing a parse-tree for each. Every phrase is given a sentiment label. The treebank produced has much more finely grained sentiment labels than the original corpus.

\begin{wrapfigure}{l}{0.6\textwidth}
    \centering
    \includegraphics[width=0.6\textwidth]{literature_review/sample_treebank.PNG}
    \caption{Sample of a labelled sentence in the Stanford NLP Sentiment Treebank \cite{stanfordSentiment2013}}
\end{wrapfigure}

The Sentiment Analyser has reported accuracy of 85.4\% in single sentence positive/negative classification.
The Stanford NLP Sentiment Analyzer was used for basic sentiment analysis of the tweets. It provides the following sentiment judgements: very positive, positive, neutral, negative and very negative.

Classifying a neutral judgment as a non-review and a positive/negative judgment as review was considered. This is too big an assumption as reviews can of course be neutral. The Stanford NLP Sentiment Analyzer may be used at a later stage, when the tweets have already been identified as reviews, for classifying the reviews as positive, negative or neutral.

\section{Recommender Systems}
\section{Tweet Classification}